https://en.wikipedia.org/wiki/Percent-encoding#Percent-encoding_reserved_characters
>>> import urllib.parse
>>> urllib.parse.quote('*%&')
'%2A%25%26'
>>> urllib.parse.quote('*%& ')
'%2A%25%26%20'
>>> urllib.parse.quote_plus('*%& ')
'%2A%25%26+'


SSL Cipher Suites
http://bugs.python.org/issue20995


Actually getting the list of TSBs is not that hard. It's enough to issue following two cURL requests:
 1) curl "https://logineai.brocade.com/BrocadeEAI/AuthenticateUser" -c cookies.txt --compressed --data "username=yourlogin&password=yourpassword" 1>/dev/null 2>/dev/null
  2) curl "https://my.brocade.com/esservice/secure/query" -H "Content-Type: application/json" -b cookies.txt --compressed --data @req.json 2>/dev/null | python -m json.tool

   req.json file, used in the previous command is just a copy-paste from what portal requests, when a user presses "sort by Newest"

    This way one can get a nice and easy to process json file, which has all the necessary information. I'm attaching example of such query. The query response states the title of TSB, post date, and pdf URL. I think it's enough to check whether the file is new, and then download it (with yet another curl query).

     Next I am having a few uncertainties:
      * For instance how will a a script filter out the product(s) a particular TSB covers? From the first sight, I don't see an obvious pattern how files are named, so a product family could be figured out easily.
       * Another question is what a BWC value-add role will be. Sure it can launch the scripts as per above, but what else?


=====================================
Well, it's getting quite complicated with PDF D/L....

1) You need cookies for login/pass
--> curl "https://logineai.brocade.com/BrocadeEAI/AuthenticateUser" -c cookies.txt --compressed --data @user_pass

2) Using this cookies you proceed to https://my.brocade.com/wps/myportal. As you immediately get redirected into something like that
https://my.brocade.com/wps/myportal/myb/home/!ut/p/z1/<bunch of symbols 1>/ you will need to add "-L" option which makes curl follow redirects
--> curl -L -v -b cookies.txt "https://my.brocade.com/wps/myportal" > content.html 2>log.txt

3) you grep content.html for following part:
​<!-- End new code --><!-- End of utility nav -->
<script type="text/javascript">
var d = new Date();
d.setTime(d.getTime() + (3600*1000)); // 1 hour 
var expires = "expires=" + d.toUTCString();
document.cookie="mybrocInfo=fn=Alexander,ln=Kurakin,em=akurakin,brEntitlement=<bunch of symbols 2>,groups=<bunch of symbols 3>;path=/;domain=.brocade.com;"+expires;         
</script>
My experiments have shown that you only need following part.
brEntitlement=<bunch of symbols 2>

4) Next you need to supply it as cookie:
​curl "https://www.brocade.com/content/dam/secure-external/documents/technical-service-bulletin/TSB-2011-102-2-A.pdf" --compressed -H "Cookie: mybrocInfo=brEntitlement=<bunch of symbols 2>" > file.pdf

5) Profit. file.pdf has content of requested TSB

First good thing that brEntitlement looks static to me as it didn't change during the time I was making my research. I'll try maybe tomorrow and see if it changes. Likely not. I'll call it a minor security flaw as when brEntitlement anyone can DL everything that entitlement grants access to :)
Secondly, another good thing is that you only need to go thru 1-3 once and only vary 4) slightly for different TSBs

P.S. I have no idea how to do this flow in python :)

                                       //Alex
